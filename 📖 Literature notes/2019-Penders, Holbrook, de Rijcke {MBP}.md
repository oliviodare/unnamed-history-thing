---
title: Rinse and Repeat. Understanding the Value of Replication across Different Ways of Knowing
authors: Penders, Holbrook, de Rijcke
year: 2019
publication: Publications
doi: 10.3390/publications7030052
url: https://www.mdpi.com/2304-6775/7/3/52
---


# Rinse and Repeat: Understanding the Value of Replication across Different Ways of Knowing
**Take-home message**:  The most heavy metal defence of the humanities and epistemic pluralism 🤟🏻. Drawing on Leonelli and Collins, they argue that (a) replication does not imply quality, (b) replication is tied within a very specific notion of accountability, (c) arguing for replication as a value to be implemented accross the board is a political argument that threatens epistemic diversity

## Reading notes

> In this article, we argue that openness does not guarantee replication. Further, building from our earlier work [8,9], we argue that replication and replicability are not always possible, regardless of how much openness one can muster. Beyond the purely epistemic question of whether replication is possible across different fields of research, we also argue that the replication drive qua policy for research is especially questionable in the hermeneutical social sciences and humanities.



> In essence, we argue that replication talk, replicatory expectations, and replication and replicability policies should be contextualised in relation to specific epistemic communities, rather than applied across the board, as if there were a single approach to knowledge and truth. This more context-sensitive appreciation of replication may offer a better understanding of how we should understand and mobilise openness. After all, open scholarship, open science and replication are not only epistemic, but also ethico-political projects, pursuing, in their broadest incarnation, a radical reform of the organisation of science and scholarship in general and the ways in which researchers give account of what they do and how they can be held accountable.



> Regardless of the definition used, it is important to note that neither ‘replicable’ nor ‘reproducible’ is a synonym for ‘true’, because, as Leek and Peng [19], Penders and Janssens [20] and Devezer et al. [21]1 argue replicable, and even replicated, research can be wrong.


Reproducibility/replicability is not a recipe for success.  

Consensus does not imply truth.

> Collins thus demonstrates practical limits to replicability: not everything can be documented so that others can repeat it. Without reaching consensus on what the ‘right’ result is, no consensus on the ‘right’ approach can be reached (see also [28]).

 I don't understand this fully - do they mean to say that the consensus on the result precedes the approach to get it?

> In non-standard experiments and non-experimental systems, replicability exists as a theoretical possibility. However, because of the lack of control researchers have over the environment in which research takes place, actual replication is contingent on circumstances beyond their control.



> In the same report (on quality, standards and rigour), Comaroff [35] dives into social anthropology to conclude that ethnographers and participant-observers can and should devote a lot more attention to explicate their procedures fully, not because it would create replicability but because it would allow scrutiny. This is in line with Wythoff [36], who writes “[M]ethod is interesting in the humanities not because it makes possible replicability and corroboration as it does in the sciences, but because it allows us to produce useful portraits of the work we do: our assumptions, our tools, and the assumptions behind our tools.” (p. 295)

 Repeating, being transparent about one's methods and assumptions, sharing pieces of our process of knowledge-making look different between disciplines, and while the humanities should probably do it (and already do!), it doesn't mean we should equate it with the concept of 'reproducibility' as used in the humanities.

> We suggest, however, that this overstates the case. Successful replication of a study in the humanities would increase our confidence in the reliability of the results—that is, in our ability to replicate the study. However, the reliability of a study does not make it more likely that the results of the original study are correct (true). Peels and Bouter do admit that a study and its replication could both be wrong in the sense that they could be equally biased, but they neglect that both could be wrong in the sense of yielding results that are simply false. The value of a successful replication (with a result that overlaps sufficiently with the original) or a failed replication (with a result that differs from the original) in the humanities or hermeneutical social sciences is not universal. In all cases, it is important to note that a failed replication does not constitute bad science, a situation shared by all disciplines. Where Leonelli argued that replicability does not constitute a valid quality criterion for science and can be considered variable across epistemic cultures, Leung argued that for qualitative research, equating reliability and replicability is “challenging and epistemologically counter-intuitive” [39].


Could we imagine another element to relate reproducibility to, instead of to truth? Could we imagine (in fact, *reinforce* the already exisiting relation) reproducibility related to collaborative work, epistemic diverstiy?  

Concretely, could we use (some) of the tools, concepts of the natural sciences 'reproducibility' for a very humanities- (and beyond) specific notions of what counts are good research?

> Ethnographic research, interpretative sociology, and many more highly empirical research approaches do not pursue replication and are, in the definition by Peels and Bouter (as well as all others) irreplicable. That does not mean that the products of this type of research are not subject to critical scrutiny or do not need to live up to expectations of quality and rigour. Rather, the pursuit of rigour is cast in terms of accountability, rather than replicability.



> Ethnographic research, interpretative sociology, and many more highly empirical research approaches do not pursue replication and are, in the definition by Peels and Bouter (as well as all others) irreplicable. That does not mean that the products of this type of research are not subject to critical scrutiny or do not need to live up to expectations of quality and rigour. Rather, the pursuit of rigour is cast in terms of accountability, rather than replicability.

 voilà, simple.

> Policies suggesting, requiring or demanding replicability, or even successful replication (or plain ‘replication’ in the definition by Bollen, see Section 1), impose monism [40]. They inadvertently, or purposefully, claim that one set of epistemic cultures is superior to another, delegitimising the latter.

 This paper is heavymetal.

> Leonelli hints at this in her critique of replication [29], that when researchers realise that replication cannot be an indicator of quality, they:
>> instead devote care and critical thinking on documenting data production processes, examining the variation among their materials and environmental conditions, and strategize about data preservation and dissemination. Within qualitative research traditions, explicitly side-stepping [replicability] has helped researchers to improve the reliability and accountability of their research practices and data”. (p. 14)

 Important, forms of accountability and quality differ, and why not exporting some of the care in the humanities to the natural sciences?

> It is one thing for researchers to virtue signal openness in exchanges on Twitter. It is something decidedly different to advocate for policies that would force subgroups of researchers to abandon the disciplinary standards of their fields.

 absolute golden mic-drop
